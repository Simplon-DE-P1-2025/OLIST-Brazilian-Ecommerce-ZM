# ğŸ›ï¸ OLIST Brazilian Ecommerce - Analyse de DonnÃ©es

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-2.0+-green.svg)](https://pandas.pydata.org/)
[![SQLite](https://img.shields.io/badge/SQLite-3-orange.svg)](https://www.sqlite.org/)
[![Marimo](https://img.shields.io/badge/Marimo-Interactive-purple.svg)](https://marimo.io/)

Projet d'analyse complÃ¨te des donnÃ©es de l'e-commerce brÃ©silien **OLIST**, incluant l'extraction, la transformation (ETL), le chargement en base de donnÃ©es SQLite, et l'exploration interactive des donnÃ©es via des notebooks **Marimo**.

## ğŸ“Š AperÃ§u du Projet

Ce projet exploite un dataset public de Kaggle contenant les donnÃ©es d'**OLIST**, le plus grand marketplace d'e-commerce du BrÃ©sil. Le dataset comprend :

- **100 000+ commandes** effectuÃ©es entre 2016 et 2018
- **32 000+ produits** rÃ©partis dans 73 catÃ©gories
- **9 fichiers CSV** interconnectÃ©s (commandes, clients, produits, avis, paiements, etc.)
- **1 million+ d'enregistrements gÃ©ographiques** pour l'analyse spatiale

### ğŸ¯ Objectifs du Projet

- âœ… **Extraction automatisÃ©e** des donnÃ©es depuis Kaggle via API
- âœ… **Transformation et nettoyage** des donnÃ©es (ETL complet)
- âœ… **ModÃ©lisation relationnelle** et chargement en base SQLite
- âœ… **Exploration interactive** avec notebooks Marimo
- âœ… **Indexation optimisÃ©e** pour des requÃªtes SQL performantes
- âœ… **Traduction des catÃ©gories** (portugais â†’ anglais)
- âœ… **DÃ©doublonnage gÃ©ographique** et standardisation des donnÃ©es


## ğŸš€ Installation & Configuration

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Git
- Un compte Kaggle (pour tÃ©lÃ©charger les donnÃ©es)

---

### 1ï¸âƒ£ Cloner le Repository

```bash
git clone https://github.com/Simplon-DE-P1-2025/OLIST-Brazilian-Ecommerce-ZM.git
cd OLIST-Brazilian-Ecommerce-ZM
```

---

### 2ï¸âƒ£ CrÃ©er et Activer l'Environnement Virtuel

**Sur Windows (PowerShell) :**
```powershell
python -m venv .venv
.\.venv\Scripts\activate.ps1
```

**Sur macOS/Linux :**
```bash
python -m venv .venv
source .venv/bin/activate
```

---

### 3ï¸âƒ£ Installer les DÃ©pendances

```bash
pip install -r requirements.txt
```

**DÃ©pendances installÃ©es :**
- `kaggle` : API pour tÃ©lÃ©charger les donnÃ©es
- `pandas` : Manipulation et transformation de donnÃ©es
- `marimo` : Notebooks interactifs (alternative Ã  Jupyter)
- `sqlalchemy` : ORM pour la base de donnÃ©es SQLite
- `matplotlib` : Visualisation de donnÃ©es
- `python-dotenv` : Gestion des variables d'environnement

---

### 4ï¸âƒ£ Configurer les Credentials Kaggle

#### **Option 1 : Via le fichier `.env`** (RecommandÃ©)

1. Allez sur [https://www.kaggle.com/settings/account](https://www.kaggle.com/settings/account)
2. Cliquez sur **"Create New API Token"**
3. RÃ©cupÃ©rer le token.
4. CrÃ©ez un fichier `.env` Ã  la racine du projet :

```env
KAGGLE_USERNAME=votre_username
KAGGLE_KEY=votre_api_key
```

âš ï¸ **Important** : Ne commitez jamais le fichier `.env` (dÃ©jÃ  dans `.gitignore`)

---

## ğŸ“¥ TÃ©lÃ©charger et Extraire les DonnÃ©es

Une fois les credentials configurÃ©es, exÃ©cutez le script d'extraction :

```bash
python src/extract.py
```

**Ce que fait ce script :**
- âœ… Authentification automatique avec l'API Kaggle
- âœ… TÃ©lÃ©chargement du dataset complet (`olistbr/brazilian-ecommerce`)
- âœ… Extraction automatique des fichiers ZIP
- âœ… Stockage dans `data/raw/`
- âœ… Affichage du rÃ©capitulatif des fichiers et tailles

**RÃ©sultat attendu :**

```
ğŸ“‹ Credentials dÃ©tectÃ©es :
   - Username: votre_username
   - Key: abcdef1234567890...
â¬‡ï¸  TÃ©lÃ©chargement de olistbr/brazilian-ecommerce...
âœ… TÃ©lÃ©chargement et extraction terminÃ©s !
ğŸ“¦ Fichiers rÃ©cupÃ©rÃ©s :
   - olist_customers_dataset.csv (8.62 MB)
   - olist_orders_dataset.csv (16.84 MB)
   - olist_order_items_dataset.csv (14.72 MB)
   ...
```

### ğŸ“‚ Fichiers TÃ©lÃ©chargÃ©s

| Fichier | Taille | Lignes | Description |
|---------|--------|--------|-------------|
| `olist_customers_dataset.csv` | 8.62 MB | 99,441 | Informations clients (ID, localisation) |
| `olist_orders_dataset.csv` | 16.84 MB | 99,441 | Commandes (dates, statuts) |
| `olist_order_items_dataset.csv` | 14.72 MB | 112,650 | Articles commandÃ©s (prix unitaire) |
| `olist_order_payments_dataset.csv` | 5.51 MB | 103,886 | MÃ©thodes de paiement |
| `olist_order_reviews_dataset.csv` | 13.78 MB | 99,224 | Avis clients (notes, commentaires) |
| `olist_products_dataset.csv` | 2.27 MB | 32,951 | Produits (catÃ©gories, dimensions) |
| `olist_geolocation_dataset.csv` | 58.44 MB | 1,000,163 | CoordonnÃ©es GPS par code postal |
| `olist_sellers_dataset.csv` | 0.17 MB | 3,095 | Vendeurs (localisation) |
| `product_category_name_translation.csv` | 0.00 MB | 71 | Traduction portugais â†’ anglais |

---

## ğŸ”„ Transformation ETL et Chargement en Base de DonnÃ©es

Le notebook Marimo `notebooks/explore.py` contient tout le pipeline ETL pour transformer et charger les donnÃ©es dans une base SQLite.

### Lancer le Notebook Interactif

```bash
marimo edit notebooks/explore.py
```

Le notebook s'ouvrira dans votre navigateur avec une interface interactive.

### ğŸ“‹ Ã‰tapes du Pipeline ETL

#### **1. Traduction des CatÃ©gories Produits**
- Fusion avec `product_category_name_translation.csv`
- Conversion du portugais vers l'anglais
- Remplissage des valeurs manquantes par `"unknown"`

#### **2. Nettoyage des DonnÃ©es Produits**
- Remplissage des valeurs numÃ©riques manquantes (poids, dimensions) par `0`
- Standardisation des types de donnÃ©es

#### **3. Conversion des Dates (Commandes)**
- Conversion de 5 colonnes de dates de `object` vers `datetime64[ns]` :
  - `order_purchase_timestamp`
  - `order_approved_at`
  - `order_delivered_carrier_date`
  - `order_delivered_customer_date`
  - `order_estimated_delivery_date`

#### **4. Nettoyage des Avis Clients**
- Remplacement des valeurs `NaN` par des chaÃ®nes vides
- Nettoyage des caractÃ¨res spÃ©ciaux dans les commentaires
- Remplacement des guillemets doubles par des simples
- Suppression des retours Ã  la ligne

#### **5. DÃ©doublonnage GÃ©ographique**
- **ProblÃ¨me initial** : 1 million+ de lignes avec duplicatas de codes postaux
- **Solution** : Groupement par `geolocation_zip_code_prefix` + moyenne des coordonnÃ©es
- **RÃ©sultat** : RÃ©duction Ã  ~19,000 codes postaux uniques (**-98% de lignes**)

#### **6. CrÃ©ation de la Base SQLite**
- CrÃ©ation du fichier `olist.db` Ã  la racine
- Insertion de 8 tables :
  - `orders` (table de faits centrale)
  - `order_items` (table de liaison)
  - `products`
  - `customers`
  - `sellers`
  - `order_payments`
  - `order_reviews`
  - `geolocation`

#### **7. Indexation pour Performances**
- CrÃ©ation de 10 index sur les clÃ©s primaires et Ã©trangÃ¨res
- Optimisation des jointures SQL futures

---

## ğŸ“ Structure du Projet

```
OLIST-Brazilian-Ecommerce-ZM/
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â””â”€â”€ extract.py              # Script d'extraction depuis Kaggle
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â””â”€â”€ raw/                    # DonnÃ©es brutes tÃ©lÃ©chargÃ©es (9 CSV)
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ explore.py              # Notebook Marimo interactif (ETL complet)
â”‚   â””â”€â”€ __marimo__/
â”‚       â””â”€â”€ session/
â”‚           â””â”€â”€ explore.py.json # Ã‰tat de session Marimo
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ .env                     # Variables d'environnement (Kaggle API)
â”œâ”€â”€ ğŸ“„ .gitignore              # Fichiers ignorÃ©s par Git
â”œâ”€â”€ ğŸ“„ LICENSE                 # Licence MIT
â”œâ”€â”€ ğŸ“„ README.md               # Ce fichier
â””â”€â”€ ğŸ—„ï¸ olist.db               # Base de donnÃ©es SQLite (gÃ©nÃ©rÃ©e aprÃ¨s ETL)
```

---

## ğŸ”§ Utilisation du Projet

### Workflow Complet

#### **Ã‰tape 1 : Extraction**
```bash
python src/extract.py
```
â†³ TÃ©lÃ©charge les donnÃ©es dans `data/raw/`

#### **Ã‰tape 2 : Exploration et ETL**
```bash
marimo edit notebooks/explore.py
```
â†³ Lance le notebook interactif dans le navigateur

**Dans le notebook :**
1. ExÃ©cutez les cellules sÃ©quentiellement (â¯ï¸ bouton play)
2. Visualisez l'aperÃ§u des donnÃ©es
3. Lancez les transformations ETL
4. VÃ©rifiez les rapports de validation
5. CrÃ©ez la base de donnÃ©es `olist.db`

#### **Ã‰tape 3 : RequÃªtes SQL (Exemple)**
```bash
sqlite3 olist.db
```

```sql
-- Top 5 des catÃ©gories les plus vendues
SELECT 
    p.product_category_name_english,
    COUNT(DISTINCT oi.order_id) as nb_commandes,
    SUM(oi.price) as revenue_total
FROM order_items oi
JOIN products p ON oi.product_id = p.product_id
GROUP BY p.product_category_name_english
ORDER BY revenue_total DESC
LIMIT 5;
```

---

## ğŸ—‚ï¸ SchÃ©ma Relationnel de la Base de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  customers  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤    orders    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ order_items  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                         â”‚
                               â”‚                         â”‚
                               â–¼                         â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚order_paymentsâ”‚         â”‚   products   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                         
                               â”‚                         
                               â–¼                         â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚order_reviews â”‚         â”‚   sellers    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ geolocation  â”‚ (Table de rÃ©fÃ©rence)
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ClÃ©s Primaires :**
- `orders.order_id`
- `customers.customer_id`
- `products.product_id`
- `sellers.seller_id`
- `geolocation.geolocation_zip_code_prefix`

**ClÃ©s Ã‰trangÃ¨res (order_items) :**
- `order_id` â†’ `orders.order_id`
- `product_id` â†’ `products.product_id`
- `seller_id` â†’ `sellers.seller_id`

---

## ğŸ“Š Insights ClÃ©s IdentifiÃ©s

### 1. **GranularitÃ© des DonnÃ©es**
- La table `order_items` contient **plusieurs lignes par commande** (1 ligne = 1 article)
- Pour obtenir le montant total d'une commande : agrÃ©gation requise (`SUM(price)`)

### 2. **MÃ©thodes de Paiement**
- **Dominance** : Carte de crÃ©dit (`credit_card`) et Boleto (paiement brÃ©silien)
- Les autres mÃ©thodes sont marginales (<5%)

### 3. **Traduction Obligatoire**
- Les catÃ©gories produits sont en **portugais** (ex : `cama_mesa_banho`)
- Utilisation du fichier de traduction pour analyses en anglais

### 4. **QualitÃ© des DonnÃ©es**
- **Dates manquantes** : Certaines commandes n'ont pas de date de livraison (commandes annulÃ©es)
- **Commentaires vides** : ~50% des avis n'ont pas de texte (seulement une note)

### 5. **Optimisation GÃ©ographique**
- RÃ©duction de **1 million â†’ 19,000 lignes** aprÃ¨s dÃ©doublonnage
- Gain de **98%** en volumÃ©trie

---



## ğŸ“¦ DÃ©pendances

| Paquet | Description |
|--------|-------------|
| `kaggle` | API Kaggle pour tÃ©lÃ©charger les donnÃ©es |
| `pandas` | Manipulation et analyse de donnÃ©es |
| `marimo` | Notebooks interactifs (alternative Ã  Jupyter) |
| `sqlalchemy` | ORM pour base de donnÃ©es SQLite |
| `matplotlib` | Visualisation de donnÃ©es |
| `python-dotenv` | Gestion des variables d'environnement |

Voir `requirements.txt` pour la liste complÃ¨te.

---


## ğŸ‘¤ Auteur

**Zoubir MABED**

ğŸ“§ **Email :** [mabedzoubir05@gmail.com](mailto:mabedzoubir05@gmail.com)

ğŸ“ **Formation :** Data Engineering - Simplon (Promotion 2026)
